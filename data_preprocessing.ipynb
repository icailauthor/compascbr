{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "In this notebook we merge sex and marital status information from the ```compas.db``` file, provided by ProPublica in their 2016 article, to the information from the ```features_before_on.csv``` file, provided by Rudin et al. in their 2019 article, which is a version of the ProPublica dataset that is supplemented with probation data they purchased. Then, we further combine it with the recidivism and violent recidivism outcomes, as computed by Rudin et al. based on their expanded dataset. The result is then saved to ```rstats.csv```. \n",
    "\n",
    "In order to generate the ```features_before_on.csv``` file, download the repository at https://github.com/beauCoker/age_of_unfairness, and place the required data files as instructed in their readme. Then, run the ```db2csv.r``` file and then the ```Table_construction.rmd``` file. This creates a variable titled ```features_before_on``` and ```outcomes``` â€“ save these ```csv``` files and use in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the ProPublica frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_database.db' with the path to your .db file\n",
    "database_path = 'data/compas.db'\n",
    "\n",
    "# Establish a connection to the database\n",
    "conn = sqlite3.connect(database_path)\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Extract the people and compas tables from the database. \n",
    "people = pd.read_sql_query(f\"SELECT * FROM people\", conn)\n",
    "compas = pd.read_sql_query(f\"SELECT * FROM compas\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Rename the 'id' column in people to 'person_id', for merging with other tables.\n",
    "people = people.rename(columns={'id': 'person_id'})\n",
    "\n",
    "# Select the columns of interest. \n",
    "people = people[['person_id', 'sex']]\n",
    "compas = compas[['person_id', 'marital_status']]\n",
    "\n",
    "# Change 'sex' column values to 1, for 'Male', and 0, for 'Female'.\n",
    "people[\"sex\"] = people[\"sex\"].replace({'Male' : 1, 'Female' : 0})\n",
    "people.rename(columns={\"sex\": \"male\"}, inplace=True)\n",
    "\n",
    "# Remove rows from compas that have an \"Unknown\" marital_status.\n",
    "compas = compas[compas[\"marital_status\"] != \"Unknown\"]\n",
    "\n",
    "# Change 'marital_status' column values to 1 and 0, binarily indicating relationship status. \n",
    "r_dict = {\n",
    "    'Single' : 0,   \n",
    "    'Divorced' : 0,\n",
    "    'Significant Other' : 1,\n",
    "    'Married' : 1,\n",
    "    'Separated' : 0,\n",
    "    'Widowed' : 0\n",
    "}\n",
    "compas[\"marital_status\"] = compas[\"marital_status\"].replace(r_dict)\n",
    "compas.rename(columns={\"marital_status\": \"partnered\"}, inplace=True)\n",
    "\n",
    "# Each person has at least three rows in the compas df, \n",
    "# corresponding to the three different risk scores. \n",
    "# Since some people were scored multiple times, some \n",
    "# persons have more than three rows, and in some instances\n",
    "# their partnered status changed between scorings. \n",
    "# We will simply pick the first value of the variable.\n",
    "# Since there are few rows with multiple scorings, and even\n",
    "# fewer with changing partnered status inbetween scorings,\n",
    "# this has a negligible impact. \n",
    "desc = compas.groupby('person_id')\n",
    "d = [[key, item[\"partnered\"].iloc[0]] for key, item in desc]\n",
    "compas = pd.DataFrame(d, columns=['person_id', 'partnered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the frames from Rudin et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_before_on = pd.read_csv('data/rudin/features_before_on.csv')\n",
    "outcomes = pd.read_csv('data/rudin/outcomes.csv')\n",
    "\n",
    "# Rename the risk score columns. \n",
    "rename_cols = {\n",
    "       'Risk of Failure to Appear_decile_score' : 'fta_ds',\n",
    "       'Risk of Failure to Appear_raw_score' : 'fta_rs',\n",
    "       'Risk of Recidivism_decile_score' : 'grecid_ds', \n",
    "       'Risk of Recidivism_raw_score' : 'grecid_rs',\n",
    "       'Risk of Violence_decile_score' : 'vrecid_ds', \n",
    "       'Risk of Violence_raw_score' : 'vrecid_rs', \n",
    "}\n",
    "features_before_on.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# Drop the temporal information. \n",
    "dropcols = ['screening_date', 'first_offense_date',\n",
    "       'current_offense_date', 'before_cutoff_date']\n",
    "features_before_on.drop(dropcols, axis='columns', inplace=True)\n",
    "\n",
    "# Drop the screening date column. \n",
    "outcomes = outcomes.drop(['screening_date'], axis='columns')\n",
    "\n",
    "# Some people have multiple screenings, and so have multiple outcomes associated. \n",
    "# We simply pick the first of these label occurrances to use for our analysis. \n",
    "desc = outcomes.groupby('person_id')\n",
    "d = [[key, item[\"recid\"].iloc[0], item[\"recid_violent\"].iloc[0]] for key, item in desc]\n",
    "outcomes = pd.DataFrame(d, columns=['person_id', 'recid', 'recid_violent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the frames, do some final processing, and write to output ```csv```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing frames to csv files.\n"
     ]
    }
   ],
   "source": [
    "# Merge the frames\n",
    "mdf = features_before_on.merge(people, on='person_id', how='left')\n",
    "mdf = mdf.merge(compas, on='person_id', how='left')\n",
    "mdf = mdf.merge(outcomes, on='person_id', how='left')\n",
    "\n",
    "# Drop the 'p_famviol_arrest', as it always equals 0.\n",
    "mdf = mdf.drop(['p_famviol_arrest'], axis='columns')\n",
    "\n",
    "# Remove rows with negative decile scores.\n",
    "mdf = mdf[mdf[\"fta_ds\"] > -1]\n",
    "mdf = mdf[mdf[\"grecid_ds\"] > -1]\n",
    "mdf = mdf[mdf[\"vrecid_ds\"] > -1]\n",
    "\n",
    "# Remove rows with p_age_first_offense equal to 0.\n",
    "mdf = mdf[mdf[\"p_age_first_offense\"] > 0]\n",
    "\n",
    "# Drop rows with missing values. \n",
    "mdf = mdf.dropna()\n",
    "\n",
    "# Cast the value types in all columns in cs to int.\n",
    "cs = [c for c in mdf.columns if c not in ['grecid_rs', 'vrecid_rs']]\n",
    "for c in mdf.columns:\n",
    "    if c not in ['grecid_rs', 'vrecid_rs']:\n",
    "        mdf[c] = mdf[c].astype(int)\n",
    "\n",
    "# Drop the index column.\n",
    "mdf = mdf.drop(['person_id'], axis='columns')\n",
    "\n",
    "# Write mdf to a csv file in the 'data' subfolder. \n",
    "mdf.to_csv('data/rscores.csv', index=False)\n",
    "print(\"Finished writing frames to csv files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
